# -*- coding: utf-8 -*-
"""Complaints_BerTopic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rXUerUWpnCDpaULY3p441RLuUObcEQOB
"""

!pip install bertopic

!pip install bertopic[visualization]

import pandas as pd
import numpy as np
import json
from bertopic import BERTopic

# Opening JSON file
f = open('complaints-2021-05-14_08_16_.json')
datafile = json.load(f)
df = pd.json_normalize(datafile)

df.head()

#Assign nan in place of blanks in the body column
df[df.loc[:, '_source.complaint_what_happened'] == ''] = np.nan

# Check if blank values still exist
df[df.loc[:, '_source.complaint_what_happened'] == '']

df.shape

#Remove all rows where body column is nan
df = df[~df['_source.complaint_what_happened'].isnull()]

df.shape

# Convert body column to string for performing text operations
df['_source.complaint_what_happened'] = df['_source.complaint_what_happened'].astype(str)

# Write your function here to clean the text and remove all the unnecessary elements.
def clean_text(sent):
    sent = sent.lower() # Text to lowercase
    pattern = '[^\w\s]' # Removing punctuation
    sent = re.sub(pattern, '', sent)
    pattern = '\w*\d\w*' # Removing words with numbers in between
    sent = re.sub(pattern, '', sent)
    return sent

import re
df_clean = pd.DataFrame(df['_source.complaint_what_happened'].apply(clean_text))
# df_clean.columns = ['complaint_what_happened']

df_clean.head()

# create model
bert_model = BERTopic(verbose=True)
#convert to list
docs = df_clean['_source.complaint_what_happened'].to_list()

#bert_model.fit_transform(docs)
topics, probabilities = bert_model.fit_transform(docs)

import gensim.corpora as corpora
from gensim.models.coherencemodel import CoherenceModel

# Preprocess documents
cleaned_docs = bert_model._preprocess_text(docs)

# Extract vectorizer and tokenizer from BERTopic
vectorizer = bert_model.vectorizer_model
tokenizer = vectorizer.build_tokenizer()

# Extract features for Topic Coherence evaluation
words = vectorizer.get_feature_names_out()
tokens = [tokenizer(doc) for doc in cleaned_docs]
dictionary = corpora.Dictionary(tokens)
corpus = [dictionary.doc2bow(token) for token in tokens]
topic_words = [[words for words, _ in bert_model.get_topic(topic)]
               for topic in range(len(set(topics))-1)]

# Evaluate
coherence_model = CoherenceModel(topics=topic_words,
                                 texts=tokens,
                                 corpus=corpus,
                                 dictionary=dictionary,
                                 coherence='c_v')
coherence = coherence_model.get_coherence()
coherence

# Evaluate
u_mass_coherence_model = CoherenceModel(topics=topic_words,
                                 texts=tokens,
                                 corpus=corpus,
                                 dictionary=dictionary,
                                 coherence='u_mass')
u_mass_coherence = u_mass_coherence_model.get_coherence()
u_mass_coherence

# Evaluate
c_uci_coherence_model = CoherenceModel(topics=topic_words,
                                 texts=tokens,
                                 corpus=corpus,
                                 dictionary=dictionary,
                                 coherence='c_uci')
c_uci_coherence = c_uci_coherence_model.get_coherence()
c_uci_coherence

# Evaluate
c_npmi_coherence_model = CoherenceModel(topics=topic_words,
                                 texts=tokens,
                                 corpus=corpus,
                                 dictionary=dictionary,
                                 coherence='c_npmi')
c_npmi_coherence = c_npmi_coherence_model.get_coherence()
c_npmi_coherence

bert_model.get_topic_freq().head(11)

bert_model.get_topic(7)

bert_model.visualize_topics()

bert_model.visualize_barchart()

bert_model.visualize_heatmap()

bert_model.save("complaints_bertmodel")

