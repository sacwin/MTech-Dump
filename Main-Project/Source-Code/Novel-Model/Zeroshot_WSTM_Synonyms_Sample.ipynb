{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfDodKJL1NH2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26108ffb-296f-4389-805d-136d34d9e6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('wordnet_ic')\n",
        "from nltk.corpus import wordnet_ic\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import wordnet\n",
        "from itertools import chain\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('latest_ticket_data.csv')"
      ],
      "metadata": {
        "id": "zkr0Kc7R2pGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_only_chars(line):\n",
        "\n",
        "    clean_line = \"\"\n",
        "\n",
        "    line = line.replace(\"â€™\", \"\")\n",
        "    line = line.replace(\"'\", \"\")\n",
        "    line = line.replace(\"-\", \" \") #replace hyphens with spaces\n",
        "    line = line.replace(\"\\t\", \" \")\n",
        "    line = line.replace(\"\\n\", \" \")\n",
        "    line = line.lower()\n",
        "\n",
        "    for char in line:\n",
        "        if char in 'qwertyuiopasdfghjklzxcvbnm ':\n",
        "            clean_line += char\n",
        "        else:\n",
        "            clean_line += ' '\n",
        "\n",
        "    clean_line = re.sub(' +',' ',clean_line) #delete extra spaces\n",
        "    if clean_line[0] == ' ':\n",
        "        clean_line = clean_line[1:]\n",
        "    return clean_line"
      ],
      "metadata": {
        "id": "wKt5AnR-TZav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Description'] = df['Description'].apply(lambda x: get_only_chars(x))"
      ],
      "metadata": {
        "id": "OuDZi8vXTkKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Tokenized']=[nltk.word_tokenize(i) for i in df['Description']]"
      ],
      "metadata": {
        "id": "iB0EJWU63XKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['pos_tagged'] = [nltk.pos_tag(i) for i in df['Tokenized']]"
      ],
      "metadata": {
        "id": "tcXSr0ye3b5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['NN_tagged'] = df['pos_tagged'].apply(lambda item:[w for w,t in item if t=='NN'])"
      ],
      "metadata": {
        "id": "k8OsXCby3iwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['NN_Description'] = df.NN_tagged.map(lambda x: ' '.join(x))"
      ],
      "metadata": {
        "id": "insbKP9b3nCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words('english')\n",
        "custom_stop_words = ['hi', 'since', 'please', 'best', 'regards', 'thank', 'thanks', 'hello', 'sent', 'great', 'dear', 'help', 'kind']\n",
        "time_words = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december',\n",
        "              'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'today' , 'yesterday', 'tomorrow',\n",
        "              'hour', 'hours', 'time', 'times', 'timelines', 'date', 'day', 'days', 'am', 'pm', 'morning', 'noon', 'afternoon', 'evening',\n",
        "              'night', 'winter', 'summer', 'rain', 'cold']\n",
        "\n",
        "def remove_stop_words(text):\n",
        "    pattern = re.compile(r'\\b(' + r'|'.join(stop_words) + r')\\b\\s*')\n",
        "    text = pattern.sub('', text)\n",
        "    return text\n",
        "\n",
        "def remove_custom_words(text):\n",
        "    pattern = re.compile(r'\\b(' + r'|'.join(custom_stop_words) + r')\\b\\s*')\n",
        "    text = pattern.sub('', text)\n",
        "    return text\n",
        "\n",
        "def remove_time_words(text):\n",
        "    pattern = re.compile(r'\\b(' + r'|'.join(time_words) + r')\\b\\s*')\n",
        "    text = pattern.sub('', text)\n",
        "    return text\n",
        "\n",
        "df['NN_Description'] = df[\"NN_Description\"].map(lambda x: remove_stop_words(x))\n",
        "df['NN_Description'] = df[\"NN_Description\"].map(lambda x: remove_custom_words(x))\n",
        "df['NN_Description'] = df[\"NN_Description\"].map(lambda x: remove_time_words(x))"
      ],
      "metadata": {
        "id": "ZX8Uiht6ULEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LE = LabelEncoder()\n",
        "df['label'] = LE.fit_transform(df['Category'])"
      ],
      "metadata": {
        "id": "8asUEwKY2sK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Get_Label_Synonyms(label):\n",
        "  result=label.split(\" \")\n",
        "  wordcount=len(result)\n",
        "  synlist = []\n",
        "  if(wordcount == 1):\n",
        "    if(wordnet.synsets(label)):\n",
        "      synonyms = wordnet.synsets(label)\n",
        "      synlist = list(set(chain.from_iterable([word.lemma_names() for word in synonyms])))\n",
        "  else:\n",
        "    for j in range(0,wordcount):\n",
        "      label_j = []\n",
        "      if(wordnet.synsets(result[j])):\n",
        "        synonyms = wordnet.synsets(result[j])\n",
        "        label_j = list(set(chain.from_iterable([word.lemma_names() for word in synonyms])))\n",
        "        synlist = synlist + label_j\n",
        "  synlist = [item.replace(\"_\",\" \") for item in synlist]\n",
        "  return(synlist)"
      ],
      "metadata": {
        "id": "-KKh_mRJsBy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelList = df['Category'].unique().tolist()"
      ],
      "metadata": {
        "id": "VShSKA_3qgea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Get_Label_Browns(label):\n",
        "  result=label.split(\" \")\n",
        "  wordcount=len(result)\n",
        "  synlist = []\n",
        "  if(wordcount == 1):\n",
        "    if(wordnet.synsets(label)):\n",
        "      synonyms = wordnet.synsets(label)\n",
        "      synlist = list(set(chain.from_iterable([word.lemma_names() for word in synonyms])))\n",
        "  else:\n",
        "    for j in range(0,wordcount):\n",
        "      label_j = []\n",
        "      if(wordnet.synsets(result[j])):\n",
        "        synonyms = wordnet.synsets(result[j])\n",
        "        label_j = list(set(chain.from_iterable([word.lemma_names() for word in synonyms])))\n",
        "        synlist = synlist + label_j\n",
        "  synlist = [item.replace(\"_\",\" \") for item in synlist]\n",
        "  return(synlist)"
      ],
      "metadata": {
        "id": "bJVhjpxye6cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getSynonymKeywords(labelList):\n",
        "  length=len(labelList)\n",
        "  topics=[]\n",
        "  for i in range(0,length):\n",
        "    label_i = Get_Label_Synonyms(labelList[i])\n",
        "    t = ' '.join(str(x) for x in label_i)\n",
        "    u = ' '.join(set(t.split()))\n",
        "    topics.append(u)\n",
        "  return(topics)"
      ],
      "metadata": {
        "id": "cJxJxwC0ymvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getBrownKeywords(labelList):\n",
        "  length=len(labelList)\n",
        "  topics=[]\n",
        "  for i in range(0,length):\n",
        "    label_i = Get_Label_Browns(labelList[i])\n",
        "    t = ' '.join(str(x) for x in label_i)\n",
        "    u = ' '.join(set(t.split()))\n",
        "    topics.append(u)\n",
        "  return(topics)"
      ],
      "metadata": {
        "id": "hUG79Th-ex9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getKeywords(labelList,keywordsType):\n",
        "  topics=[]\n",
        "  if(keywordsType=='brown'):\n",
        "    topics=getBrownKeywords(labelList)\n",
        "    return(topics)\n",
        "  if(keywordsType=='synonym'):\n",
        "    topics=getSynonymKeywords(labelList)\n",
        "    return(topics)"
      ],
      "metadata": {
        "id": "ZUIYYPuoNMDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topics = getKeywords(labelList,'synonym')\n",
        "print(topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7bUg-C8q69A",
        "outputId": "9998aa1e-f337-48af-91cb-c8a5ad11722b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['practical applications coating application programme covering lotion diligence program', 'database', 'web meshwork mesh electronic network net meshing', 'drug exploiter sustenance abuser alimony upkeep maintenance criminal care substance user sustentation sustainment', 'system department security measures measure protection surety certificate']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate samples that contains K samples of each class\n",
        "def gen_sample(df, sample_size, num_classes):\n",
        "\n",
        "    df_1 = df[(df[\"label\"]<num_classes + 1)].reset_index().drop([\"index\"], axis=1).reset_index().drop([\"index\"], axis=1)\n",
        "    train = df_1[df_1[\"label\"] == np.unique(df_1['label'])[0]].sample(sample_size)\n",
        "\n",
        "    train_index = train.index.tolist()\n",
        "\n",
        "    for i in range(1,num_classes):\n",
        "        train_2 = df_1[df_1[\"label\"] == np.unique(df_1['label'])[i]].sample(sample_size)\n",
        "        train = pd.concat([train, train_2], axis=0)\n",
        "        train_index.extend(train_2.index.tolist())\n",
        "\n",
        "    test = df_1[~df_1.index.isin(train_index)]\n",
        "\n",
        "    return train, test"
      ],
      "metadata": {
        "id": "FoBJD13Rku67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
        "dog = wordnet.synset('dog.n.01')\n",
        "cat = wordnet.synset('cat.n.01')\n",
        "#dog.res_similarity(cat, brown_ic)\n",
        "dog.lch_similarity(cat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr3hXnuAlyC0",
        "outputId": "b5cbdae5-dcba-42a6-e28d-c9018d554074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet_ic is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0281482472922856"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def WordnetShortestPath_labelscore(a,topics):\n",
        "  lowest_netavg=100\n",
        "  lowest_label=0\n",
        "  label=-1\n",
        "  #print(a)\n",
        "  words = nltk.word_tokenize(a)\n",
        "  for z in topics:\n",
        "    total=0\n",
        "    counter=0\n",
        "    #print(z)\n",
        "    for x in z:\n",
        "      count=0\n",
        "      avg=0\n",
        "      sum=0\n",
        "      for y in words:\n",
        "        if(wordnet.synsets(x) and wordnet.synsets(y)):\n",
        "          syn1 = wordnet.synsets(x)[0]\n",
        "          syn2 = wordnet.synsets(y)[0]\n",
        "          if(syn1.pos() == 'n' and syn2.pos() == 'n'):\n",
        "            #print(\"Shortest path between \",x,\" and \",y,\" is: \", syn1.shortest_path_distance(syn2))\n",
        "            sum=sum+syn1.shortest_path_distance(syn2)\n",
        "            count=count+1\n",
        "      if(count==0):\n",
        "        avg=0\n",
        "      else:\n",
        "        avg=sum/count\n",
        "      total=total+avg\n",
        "      counter=counter+1\n",
        "      #print(sum)\n",
        "      #print(count)\n",
        "      #print(avg)\n",
        "    if(counter==0):\n",
        "      netavg=0\n",
        "    else:\n",
        "      netavg=total/counter\n",
        "    #print(counter)\n",
        "    #print(\"Total score for \",z,\" is: \",total)\n",
        "    #print(\"Net average for \",z,\" is: \",netavg)\n",
        "    label=label+1\n",
        "    if(netavg<lowest_netavg):\n",
        "      lowest_netavg=netavg\n",
        "      lowest_label=label\n",
        "      #print(\"label: \",label,\" has shortest path value: \",lowest_netavg)\n",
        "  return lowest_label,lowest_netavg"
      ],
      "metadata": {
        "id": "saMjRxel4BqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def WordnetLeacock_labelscore(a,topics):\n",
        "  lowest_netavg=100\n",
        "  lowest_label=0\n",
        "  label=-1\n",
        "  #print(a)\n",
        "  words = nltk.word_tokenize(a)\n",
        "  for z in topics:\n",
        "    total=0\n",
        "    counter=0\n",
        "    #print(z)\n",
        "    for x in z:\n",
        "      count=0\n",
        "      avg=0\n",
        "      sum=0\n",
        "      for y in words:\n",
        "        if(wordnet.synsets(x) and wordnet.synsets(y)):\n",
        "          syn1 = wordnet.synsets(x)[0]\n",
        "          syn2 = wordnet.synsets(y)[0]\n",
        "          if(syn1.pos() == 'n' and syn2.pos() == 'n'):\n",
        "            #print(\"Shortest path between \",x,\" and \",y,\" is: \", syn1.shortest_path_distance(syn2))\n",
        "            sum=sum+syn1.lch_similarity(syn2)\n",
        "            count=count+1\n",
        "      if(count==0):\n",
        "        avg=0\n",
        "      else:\n",
        "        avg=sum/count\n",
        "      total=total+avg\n",
        "      counter=counter+1\n",
        "      #print(sum)\n",
        "      #print(count)\n",
        "      #print(avg)\n",
        "    if(counter==0):\n",
        "      netavg=0\n",
        "    else:\n",
        "      netavg=total/counter\n",
        "    #print(counter)\n",
        "    #print(\"Total score for \",z,\" is: \",total)\n",
        "    #print(\"Net average for \",z,\" is: \",netavg)\n",
        "    label=label+1\n",
        "    if(netavg<lowest_netavg):\n",
        "      lowest_netavg=netavg\n",
        "      lowest_label=label\n",
        "      #print(\"label: \",label,\" has shortest path value: \",lowest_netavg)\n",
        "  return lowest_label,lowest_netavg"
      ],
      "metadata": {
        "id": "v5u9bQVhqVQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def WordnetRES_labelscore(a,topics):\n",
        "  highest_netavg=0\n",
        "  highest_label=0\n",
        "  label=-1\n",
        "  #print(a)\n",
        "  words = nltk.word_tokenize(a)\n",
        "  for z in topics:\n",
        "    total=0\n",
        "    counter=0\n",
        "    #print(z)\n",
        "    for x in z:\n",
        "      count=0\n",
        "      avg=0\n",
        "      sum=0\n",
        "      for y in words:\n",
        "        if(wordnet.synsets(x) and wordnet.synsets(y)):\n",
        "          syn1 = wordnet.synsets(x)[0]\n",
        "          syn2 = wordnet.synsets(y)[0]\n",
        "          if(syn1.pos() == 'n' and syn2.pos() == 'n'):\n",
        "            sum=sum+syn1.res_similarity(syn2, brown_ic)\n",
        "            count=count+1\n",
        "      if(count==0):\n",
        "        avg=0\n",
        "      else:\n",
        "        avg=sum/count\n",
        "      total=total+avg\n",
        "      counter=counter+1\n",
        "      #print(sum)\n",
        "      #print(count)\n",
        "      #print(avg)\n",
        "    if(counter==0):\n",
        "      netavg=0\n",
        "    else:\n",
        "      netavg=total/counter\n",
        "    #print(counter)\n",
        "    #print(\"Total score for \",z,\" is: \",total)\n",
        "    #print(\"Net average for \",z,\" is: \",netavg)\n",
        "    label=label+1\n",
        "    if(netavg>highest_netavg):\n",
        "      highest_netavg=netavg\n",
        "      highest_label=label\n",
        "      #print(\"label: \",label,\" has shortest path value: \",lowest_netavg)\n",
        "  return highest_label,highest_netavg"
      ],
      "metadata": {
        "id": "KXfGRH2LnkxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def WordnetLIN_labelscore(a,topics):\n",
        "  highest_netavg=0\n",
        "  highest_label=0\n",
        "  label=-1\n",
        "  #print(a)\n",
        "  words = nltk.word_tokenize(a)\n",
        "  for z in topics:\n",
        "    total=0\n",
        "    counter=0\n",
        "    #print(z)\n",
        "    for x in z:\n",
        "      count=0\n",
        "      avg=0\n",
        "      sum=0\n",
        "      for y in words:\n",
        "        if(wordnet.synsets(x) and wordnet.synsets(y)):\n",
        "          syn1 = wordnet.synsets(x)[0]\n",
        "          syn2 = wordnet.synsets(y)[0]\n",
        "          if(syn1.pos() == 'n' and syn2.pos() == 'n'):\n",
        "            #print(\"Shortest path between \",x,\" and \",y,\" is: \", syn1.wup_similarity(syn2))\n",
        "            sum=sum+syn1.lin_similarity(syn2, brown_ic)\n",
        "            count=count+1\n",
        "      if(count==0):\n",
        "        avg=0\n",
        "      else:\n",
        "        avg=sum/count\n",
        "      total=total+avg\n",
        "      counter=counter+1\n",
        "      #print(sum)\n",
        "      #print(count)\n",
        "      #print(avg)\n",
        "    if(counter==0):\n",
        "      netavg=0\n",
        "    else:\n",
        "      netavg=total/counter\n",
        "    #print(counter)\n",
        "    #print(\"Total score for \",z,\" is: \",total)\n",
        "    #print(\"Net average for \",z,\" is: \",netavg)\n",
        "    label=label+1\n",
        "    if(netavg>highest_netavg):\n",
        "      highest_netavg=netavg\n",
        "      highest_label=label\n",
        "      #print(\"label: \",label,\" has shortest path value: \",lowest_netavg)\n",
        "  return highest_label,highest_netavg"
      ],
      "metadata": {
        "id": "5V_Qpb68thZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def WordnetJCN_labelscore(a,topics):\n",
        "  highest_netavg=0\n",
        "  highest_label=0\n",
        "  label=-1\n",
        "  #print(a)\n",
        "  words = nltk.word_tokenize(a)\n",
        "  for z in topics:\n",
        "    total=0\n",
        "    counter=0\n",
        "    #print(z)\n",
        "    for x in z:\n",
        "      count=0\n",
        "      avg=0\n",
        "      sum=0\n",
        "      for y in words:\n",
        "        if(wordnet.synsets(x) and wordnet.synsets(y)):\n",
        "          syn1 = wordnet.synsets(x)[0]\n",
        "          syn2 = wordnet.synsets(y)[0]\n",
        "          if(syn1.pos() == 'n' and syn2.pos() == 'n'):\n",
        "            #print(\"Shortest path between \",x,\" and \",y,\" is: \", syn1.wup_similarity(syn2))\n",
        "            sum=sum+syn1.jcn_similarity(syn2, brown_ic)\n",
        "            count=count+1\n",
        "      if(count==0):\n",
        "        avg=0\n",
        "      else:\n",
        "        avg=sum/count\n",
        "      total=total+avg\n",
        "      counter=counter+1\n",
        "      #print(sum)\n",
        "      #print(count)\n",
        "      #print(avg)\n",
        "    if(counter==0):\n",
        "      netavg=0\n",
        "    else:\n",
        "      netavg=total/counter\n",
        "    #print(counter)\n",
        "    #print(\"Total score for \",z,\" is: \",total)\n",
        "    #print(\"Net average for \",z,\" is: \",netavg)\n",
        "    label=label+1\n",
        "    if(netavg>highest_netavg):\n",
        "      highest_netavg=netavg\n",
        "      highest_label=label\n",
        "      #print(\"label: \",label,\" has shortest path value: \",lowest_netavg)\n",
        "  return highest_label,highest_netavg"
      ],
      "metadata": {
        "id": "x7EpXseYtMCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def WordnetWUP_labelscore(a,topics):\n",
        "  highest_netavg=0\n",
        "  highest_label=0\n",
        "  label=-1\n",
        "  #print(a)\n",
        "  words = nltk.word_tokenize(a)\n",
        "  for z in topics:\n",
        "    total=0\n",
        "    counter=0\n",
        "    #print(z)\n",
        "    for x in z:\n",
        "      count=0\n",
        "      avg=0\n",
        "      sum=0\n",
        "      for y in words:\n",
        "        if(wordnet.synsets(x) and wordnet.synsets(y)):\n",
        "          syn1 = wordnet.synsets(x)[0]\n",
        "          syn2 = wordnet.synsets(y)[0]\n",
        "          if(syn1.pos() == 'n' and syn2.pos() == 'n'):\n",
        "            #print(\"Shortest path between \",x,\" and \",y,\" is: \", syn1.wup_similarity(syn2))\n",
        "            sum=sum+syn1.wup_similarity(syn2)\n",
        "            count=count+1\n",
        "      if(count==0):\n",
        "        avg=0\n",
        "      else:\n",
        "        avg=sum/count\n",
        "      total=total+avg\n",
        "      counter=counter+1\n",
        "      #print(sum)\n",
        "      #print(count)\n",
        "      #print(avg)\n",
        "    if(counter==0):\n",
        "      netavg=0\n",
        "    else:\n",
        "      netavg=total/counter\n",
        "    #print(counter)\n",
        "    #print(\"Total score for \",z,\" is: \",total)\n",
        "    #print(\"Net average for \",z,\" is: \",netavg)\n",
        "    label=label+1\n",
        "    if(netavg>highest_netavg):\n",
        "      highest_netavg=netavg\n",
        "      highest_label=label\n",
        "      #print(\"label: \",label,\" has shortest path value: \",lowest_netavg)\n",
        "  return highest_label,highest_netavg"
      ],
      "metadata": {
        "id": "LihS7434Nqgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ZeroShotWordnetModel(text, labelList, keywordstobeGenerated='Yes', keywordsList=[], keywordsType='synonym', posfilterType='NN', measureType='ShortestPath'):\n",
        "  if not text and not labelList:\n",
        "    print(\"Input Text and List of Label/Category names required\")\n",
        "    return()\n",
        "  else:\n",
        "    if(keywordstobeGenerated=='Yes'):\n",
        "      topics = getKeywords(labelList,keywordsType)\n",
        "    else:\n",
        "      topics = labelList\n",
        "    if(posfilterType=='NN'):\n",
        "      if(measureType=='WuPalmer'):\n",
        "        return(WordnetWUP_labelscore(text,topics))\n",
        "      if(measureType=='Resnik'):\n",
        "        return(WordnetRES_labelscore(text,topics))\n",
        "      if(measureType=='JCN'):\n",
        "        return(WordnetJCN_labelscore(text,topics))\n",
        "      if(measureType=='Lin'):\n",
        "        return(WordnetLIN_labelscore(text,topics))\n",
        "      if(measureType=='Leacock'):\n",
        "        return(WordnetLeacock_labelscore(text,topics))\n",
        "      if(measureType=='ShortestPath'):\n",
        "        return(WordnetShortestPath_labelscore(text,topics))\n"
      ],
      "metadata": {
        "id": "LQqGTWxPspyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ZeroShotWordnetModel(df['Description'][0],labelList,measureType='Leacock')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fvy3eFKE0xDc",
        "outputId": "56cb55b4-aeeb-4f07-8ee7-594271d0d2f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 0.9867316419149126)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ZeroShotWordnetModel(df['NN_Description'][0],labelList,measureType='Leacock')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuuIrlCo1hYK",
        "outputId": "799b191b-6c69-4b23-d3e4-1054a1fddcc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1.0310033595479977)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ZeroShotWordnetModel(df['Description'][0],labelList,measureType='Lin')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGtiQnIO0r7c",
        "outputId": "c74cabc9-605f-49d6-f2d9-45a2a678a526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 0.0441047053537972)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ZeroShotWordnetModel(df['NN_Description'][0],labelList,measureType='Lin')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZvJWJUN1kNq",
        "outputId": "ce3bb030-4714-41a8-89e1-5a5790cdd4d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 0.04571837058225767)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ZeroShotWordnetModel(df['Description'][0],labelList,measureType='JCN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5-Dhq7Rw5Gc",
        "outputId": "ab5aed8a-13f8-4773-b5f1-82b0c740832f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 0.04807108388377777)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ZeroShotWordnetModel(df['NN_Description'][0],labelList,measureType='JCN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMe5uS-Rw5DA",
        "outputId": "e2f3a8a3-aa66-4779-f201-6713cdb295d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 0.04915213813510252)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ZeroShotWordnetModel(df['Description'][0],labelList,measureType='Resnik')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P_7Lg_3wz8P",
        "outputId": "83553024-48bc-4407-fffa-687a84d79dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0.47857541687594535)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ZeroShotWordnetModel(df['NN_Description'][0],labelList,measureType='Resnik')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDLVEAF1w8Dk",
        "outputId": "2f2fe58e-c8cb-4034-bb1a-7123d3a64034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0.46481235684567734)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ZeroShotWordnetModel(df['Description'][0],labelList,measureType='WuPalmer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wzI74L7xswv",
        "outputId": "0b338344-6ab9-4114-f48c-1bb28fa0f093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0.22638386011349043)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ZeroShotWordnetModel(df['NN_Description'][0],labelList,measureType='WuPalmer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F-SDxuG1pyl",
        "outputId": "ca69de97-a8fc-4d20-fa77-00708d00f8cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0.231281816045838)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ZeroShotWordnetModel(df['Description'][0],labelList)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6XMIYEx1sMA",
        "outputId": "d35dd553-3bf6-453c-bb25-7c36acfc9fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 10.050925925925927)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ZeroShotWordnetModel(df['NN_Description'][0],labelList)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjoqBnA4ebpm",
        "outputId": "3c0bb1ef-6bfa-43d8-8b7f-947ee32cabe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 9.451388888888891)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data, rest = gen_sample(df, 100, 5)"
      ],
      "metadata": {
        "id": "tmmAqSOak0vC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[['NN_Leacock_Label', 'NN_Leacock_Value']] = data['NN_Description'].apply(lambda x: pd.Series(ZeroShotWordnetModel(x, labelList,measureType='Leacock')))"
      ],
      "metadata": {
        "id": "qHPJNWfW3QmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"NN_Leacock_Label\"] = data[\"NN_Leacock_Label\"].astype(int)"
      ],
      "metadata": {
        "id": "v2Jn-Oew-PkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(data['label'], data['NN_Leacock_Label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osbu7UnG-VGc",
        "outputId": "6ce74cf6-0e78-424d-e78d-2685a1371c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.152"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[['NN_Lin_Label', 'NN_Lin_Value']] = data['NN_Description'].apply(lambda x: pd.Series(ZeroShotWordnetModel(x, labelList,measureType='Lin')))"
      ],
      "metadata": {
        "id": "Ik4m-QJY7NRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"NN_Lin_Label\"] = data[\"NN_Lin_Label\"].astype(int)"
      ],
      "metadata": {
        "id": "ikVFO_l0_RtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(data['label'], data['NN_Lin_Label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwv0Zb-1_Uzp",
        "outputId": "1c8c0824-1dbd-466d-eee0-e324075aa121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.226"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[['NN_JCN_Label', 'NN_JCN_Value']] = data['NN_Description'].apply(lambda x: pd.Series(ZeroShotWordnetModel(x, labelList,measureType='JCN')))"
      ],
      "metadata": {
        "id": "1WGPi0GI7ntD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"NN_JCN_Label\"] = data[\"NN_JCN_Label\"].astype(int)"
      ],
      "metadata": {
        "id": "oJyn65aj_aeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(data['label'], data['NN_JCN_Label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCSMW2fk_bMv",
        "outputId": "feda438f-1eec-4fd0-efbe-5021d3492566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[['NN_Resnik_Label', 'NN_Resnik_Value']] = data['NN_Description'].apply(lambda x: pd.Series(ZeroShotWordnetModel(x, labelList,measureType='Resnik')))"
      ],
      "metadata": {
        "id": "5ctvZe8i7xKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"NN_Resnik_Label\"] = data[\"NN_Resnik_Label\"].astype(int)"
      ],
      "metadata": {
        "id": "5sa3gcOy_iB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(data['label'], data['NN_Resnik_Label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL_ayQq8ACa3",
        "outputId": "1745ab38-6c7b-4fb6-c599-660389e84f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.242"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[['NN_WUP_Label', 'NN_WUP_Value']] = data['NN_Description'].apply(lambda x: pd.Series(ZeroShotWordnetModel(x, labelList,measureType='WuPalmer')))"
      ],
      "metadata": {
        "id": "iZZpwWOA8TUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"NN_WUP_Label\"] = data[\"NN_WUP_Label\"].astype(int)"
      ],
      "metadata": {
        "id": "gQ3lWNGZAA_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(data['label'], data['NN_WUP_Label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcWFehVpAFSq",
        "outputId": "74d676c1-d1a5-41f9-cb7b-bcd275b60b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.224"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[['NN_WSP_Label', 'NN_WSP_Value']] = data['NN_Description'].apply(lambda x: pd.Series(ZeroShotWordnetModel(x, labelList)))"
      ],
      "metadata": {
        "id": "RbC17Tx3HKpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"NN_WSP_Label\"] = data[\"NN_WSP_Label\"].astype(int)"
      ],
      "metadata": {
        "id": "2J8jXVYc_sZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(data['label'], data['NN_WSP_Label'])"
      ],
      "metadata": {
        "id": "9V_5rDwzNbaQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a370793e-f3c8-4503-84db-a7494f491345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.196"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[ [\"WSP_Label\",\"WSP_Value\"] ] = data[\"Description\"].apply(WordnetShortestPath_labelscore).apply(pd.Series)"
      ],
      "metadata": {
        "id": "0hsX_pl1na1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"WSP_Label\"] = data[\"WSP_Label\"].astype(int)"
      ],
      "metadata": {
        "id": "R8WTnxPbneJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(data['label'], data['WSP_Label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4cJiBF4nj7E",
        "outputId": "467deab7-ec25-4dfb-d8d0-deeed2d04efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.202"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[['NN_WUP_Label', 'NN_WUP_Value']] = df['Description'].apply(lambda x: pd.Series(ZeroShotWordnetModel(x, labelList)))"
      ],
      "metadata": {
        "id": "5KEib-6R1pLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"NN_WUP_Label\"] = df[\"NN_WUP_Label\"].astype(int)"
      ],
      "metadata": {
        "id": "ZqYjbY0FHqy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(df['label'], df['NN_WUP_Label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YTXSY36Hw57",
        "outputId": "49c37b47-9442-4eec-ff43-c2c0a2ed3e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.206"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[ [\"NN_WUP_Label\",\"NN_WUP_Value\"] ] = data[\"NN_Description\"].apply(WordnetWUP_labelscore).apply(pd.Series)"
      ],
      "metadata": {
        "id": "P9YYqw-fIHb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"NN_WUP_Label\"] = data[\"NN_WUP_Label\"].astype(int)"
      ],
      "metadata": {
        "id": "ji31jGroIKGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[ [\"WUP_Label\",\"WUP_Value\"] ] = data[\"Description\"].apply(WordnetWUP_labelscore).apply(pd.Series)"
      ],
      "metadata": {
        "id": "WL63GUb7nn41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"WUP_Label\"] = data[\"WUP_Label\"].astype(int)"
      ],
      "metadata": {
        "id": "77naGVrpnq_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(data['label'], data['NN_WUP_Label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xqoh-a6sIUJM",
        "outputId": "25094570-e91c-4e20-d87a-b4a109a986ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.214"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(data['label'], data['WUP_Label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvsUuzmfnv3V",
        "outputId": "553495b0-1b14-4fdd-e760-af2d7c6992cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.198"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "VEU-WoElRLS8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41a267f8-2e40-4f3d-d73d-2fbb08f5cca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Description          Category  \\\n",
              "55    wants principles principles document thank acc...       Application   \n",
              "342   agile hello please add agile kind regards disc...       Application   \n",
              "575   card building good morning card working underg...       Application   \n",
              "515           same hi regarding complain please pm same       Application   \n",
              "221         change hi please change myself thank senior       Application   \n",
              "...                                                 ...               ...   \n",
              "1612  thursday card hello please help activate card ...  User Maintenance   \n",
              "1671  thursday february secure area good morning ple...  User Maintenance   \n",
              "1638     friday march pm card leaver care firma weekend  User Maintenance   \n",
              "1598  wednesday pm card hello si ca card assignat ca...  User Maintenance   \n",
              "1230  badge dear please help assign badge starting t...  User Maintenance   \n",
              "\n",
              "                                              Tokenized  \\\n",
              "55    [wants, principles, principles, document, than...   \n",
              "342   [agile, hello, please, add, agile, kind, regar...   \n",
              "575   [card, building, good, morning, card, working,...   \n",
              "515   [same, hi, regarding, complain, please, pm, same]   \n",
              "221   [change, hi, please, change, myself, thank, se...   \n",
              "...                                                 ...   \n",
              "1612  [thursday, card, hello, please, help, activate...   \n",
              "1671  [thursday, february, secure, area, good, morni...   \n",
              "1638  [friday, march, pm, card, leaver, care, firma,...   \n",
              "1598  [wednesday, pm, card, hello, si, ca, card, ass...   \n",
              "1230  [badge, dear, please, help, assign, badge, sta...   \n",
              "\n",
              "                                             pos_tagged  \\\n",
              "55    [(wants, VBZ), (principles, NNS), (principles,...   \n",
              "342   [(agile, IN), (hello, JJ), (please, NN), (add,...   \n",
              "575   [(card, NN), (building, NN), (good, JJ), (morn...   \n",
              "515   [(same, JJ), (hi, NN), (regarding, VBG), (comp...   \n",
              "221   [(change, NN), (hi, NN), (please, NN), (change...   \n",
              "...                                                 ...   \n",
              "1612  [(thursday, JJ), (card, NN), (hello, NN), (ple...   \n",
              "1671  [(thursday, JJ), (february, JJ), (secure, NN),...   \n",
              "1638  [(friday, JJ), (march, NN), (pm, NN), (card, N...   \n",
              "1598  [(wednesday, JJ), (pm, VB), (card, NN), (hello...   \n",
              "1230  [(badge, NN), (dear, NN), (please, NN), (help,...   \n",
              "\n",
              "                                              NN_tagged  \\\n",
              "55                                     [thank, decline]   \n",
              "342                                [please, kind, lead]   \n",
              "575      [card, building, morning, card, please, thank]   \n",
              "515                                    [hi, please, pm]   \n",
              "221                        [change, hi, please, change]   \n",
              "...                                                 ...   \n",
              "1612  [card, hello, please, floor, resolution, date,...   \n",
              "1671  [secure, area, morning, please, area, tower, t...   \n",
              "1638                   [march, pm, card, care, weekend]   \n",
              "1598  [card, hello, si, assignat, care, care, si, ca...   \n",
              "1230                [badge, dear, please, badge, today]   \n",
              "\n",
              "                             NN_Description  label  NN_WSP_Label  \\\n",
              "55                                  decline      0             2   \n",
              "342                                    lead      0             2   \n",
              "575                     card building card       0             2   \n",
              "515                                              0             0   \n",
              "221                           change change      0             2   \n",
              "...                                     ...    ...           ...   \n",
              "1612             card floor resolution head      4             2   \n",
              "1671         secure area area tower officer      4             2   \n",
              "1638                      card care weekend      4             2   \n",
              "1598  card si assignat care care si care va      4             2   \n",
              "1230                           badge badge       4             2   \n",
              "\n",
              "      NN_WSP_Value  WSP_Label  WSP_Value  NN_WUP_Label  NN_WUP_Value  \\\n",
              "55        7.708333          2   9.201389             2      0.241016   \n",
              "342       9.500000          2  10.229167             0      0.245049   \n",
              "575       7.916667          2   8.950000             4      0.317950   \n",
              "515       0.000000          2  10.083333             0      0.000000   \n",
              "221       8.625000          2   9.463542             0      0.263633   \n",
              "...            ...        ...        ...           ...           ...   \n",
              "1612      9.098958          2   9.586310             0      0.247561   \n",
              "1671      9.171875          2   9.607639             1      0.226632   \n",
              "1638      8.520833          2   9.630952             0      0.305324   \n",
              "1598      8.854167          2   9.013480             0      0.311777   \n",
              "1230     12.125000          2   9.373264             0      0.202357   \n",
              "\n",
              "      WUP_Label  WUP_Value  \n",
              "55            0   0.244646  \n",
              "342           0   0.232287  \n",
              "575           0   0.266899  \n",
              "515           1   0.220723  \n",
              "221           0   0.236450  \n",
              "...         ...        ...  \n",
              "1612          0   0.242169  \n",
              "1671          1   0.238750  \n",
              "1638          0   0.266521  \n",
              "1598          0   0.296457  \n",
              "1230          0   0.267989  \n",
              "\n",
              "[500 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-889bae7a-630e-4089-91d4-ccb3133b7f5e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Category</th>\n",
              "      <th>Tokenized</th>\n",
              "      <th>pos_tagged</th>\n",
              "      <th>NN_tagged</th>\n",
              "      <th>NN_Description</th>\n",
              "      <th>label</th>\n",
              "      <th>NN_WSP_Label</th>\n",
              "      <th>NN_WSP_Value</th>\n",
              "      <th>WSP_Label</th>\n",
              "      <th>WSP_Value</th>\n",
              "      <th>NN_WUP_Label</th>\n",
              "      <th>NN_WUP_Value</th>\n",
              "      <th>WUP_Label</th>\n",
              "      <th>WUP_Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>wants principles principles document thank acc...</td>\n",
              "      <td>Application</td>\n",
              "      <td>[wants, principles, principles, document, than...</td>\n",
              "      <td>[(wants, VBZ), (principles, NNS), (principles,...</td>\n",
              "      <td>[thank, decline]</td>\n",
              "      <td>decline</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>7.708333</td>\n",
              "      <td>2</td>\n",
              "      <td>9.201389</td>\n",
              "      <td>2</td>\n",
              "      <td>0.241016</td>\n",
              "      <td>0</td>\n",
              "      <td>0.244646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>agile hello please add agile kind regards disc...</td>\n",
              "      <td>Application</td>\n",
              "      <td>[agile, hello, please, add, agile, kind, regar...</td>\n",
              "      <td>[(agile, IN), (hello, JJ), (please, NN), (add,...</td>\n",
              "      <td>[please, kind, lead]</td>\n",
              "      <td>lead</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>2</td>\n",
              "      <td>10.229167</td>\n",
              "      <td>0</td>\n",
              "      <td>0.245049</td>\n",
              "      <td>0</td>\n",
              "      <td>0.232287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575</th>\n",
              "      <td>card building good morning card working underg...</td>\n",
              "      <td>Application</td>\n",
              "      <td>[card, building, good, morning, card, working,...</td>\n",
              "      <td>[(card, NN), (building, NN), (good, JJ), (morn...</td>\n",
              "      <td>[card, building, morning, card, please, thank]</td>\n",
              "      <td>card building card</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>7.916667</td>\n",
              "      <td>2</td>\n",
              "      <td>8.950000</td>\n",
              "      <td>4</td>\n",
              "      <td>0.317950</td>\n",
              "      <td>0</td>\n",
              "      <td>0.266899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>same hi regarding complain please pm same</td>\n",
              "      <td>Application</td>\n",
              "      <td>[same, hi, regarding, complain, please, pm, same]</td>\n",
              "      <td>[(same, JJ), (hi, NN), (regarding, VBG), (comp...</td>\n",
              "      <td>[hi, please, pm]</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>10.083333</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.220723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>change hi please change myself thank senior</td>\n",
              "      <td>Application</td>\n",
              "      <td>[change, hi, please, change, myself, thank, se...</td>\n",
              "      <td>[(change, NN), (hi, NN), (please, NN), (change...</td>\n",
              "      <td>[change, hi, please, change]</td>\n",
              "      <td>change change</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8.625000</td>\n",
              "      <td>2</td>\n",
              "      <td>9.463542</td>\n",
              "      <td>0</td>\n",
              "      <td>0.263633</td>\n",
              "      <td>0</td>\n",
              "      <td>0.236450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1612</th>\n",
              "      <td>thursday card hello please help activate card ...</td>\n",
              "      <td>User Maintenance</td>\n",
              "      <td>[thursday, card, hello, please, help, activate...</td>\n",
              "      <td>[(thursday, JJ), (card, NN), (hello, NN), (ple...</td>\n",
              "      <td>[card, hello, please, floor, resolution, date,...</td>\n",
              "      <td>card floor resolution head</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>9.098958</td>\n",
              "      <td>2</td>\n",
              "      <td>9.586310</td>\n",
              "      <td>0</td>\n",
              "      <td>0.247561</td>\n",
              "      <td>0</td>\n",
              "      <td>0.242169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1671</th>\n",
              "      <td>thursday february secure area good morning ple...</td>\n",
              "      <td>User Maintenance</td>\n",
              "      <td>[thursday, february, secure, area, good, morni...</td>\n",
              "      <td>[(thursday, JJ), (february, JJ), (secure, NN),...</td>\n",
              "      <td>[secure, area, morning, please, area, tower, t...</td>\n",
              "      <td>secure area area tower officer</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>9.171875</td>\n",
              "      <td>2</td>\n",
              "      <td>9.607639</td>\n",
              "      <td>1</td>\n",
              "      <td>0.226632</td>\n",
              "      <td>1</td>\n",
              "      <td>0.238750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1638</th>\n",
              "      <td>friday march pm card leaver care firma weekend</td>\n",
              "      <td>User Maintenance</td>\n",
              "      <td>[friday, march, pm, card, leaver, care, firma,...</td>\n",
              "      <td>[(friday, JJ), (march, NN), (pm, NN), (card, N...</td>\n",
              "      <td>[march, pm, card, care, weekend]</td>\n",
              "      <td>card care weekend</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8.520833</td>\n",
              "      <td>2</td>\n",
              "      <td>9.630952</td>\n",
              "      <td>0</td>\n",
              "      <td>0.305324</td>\n",
              "      <td>0</td>\n",
              "      <td>0.266521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1598</th>\n",
              "      <td>wednesday pm card hello si ca card assignat ca...</td>\n",
              "      <td>User Maintenance</td>\n",
              "      <td>[wednesday, pm, card, hello, si, ca, card, ass...</td>\n",
              "      <td>[(wednesday, JJ), (pm, VB), (card, NN), (hello...</td>\n",
              "      <td>[card, hello, si, assignat, care, care, si, ca...</td>\n",
              "      <td>card si assignat care care si care va</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8.854167</td>\n",
              "      <td>2</td>\n",
              "      <td>9.013480</td>\n",
              "      <td>0</td>\n",
              "      <td>0.311777</td>\n",
              "      <td>0</td>\n",
              "      <td>0.296457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>badge dear please help assign badge starting t...</td>\n",
              "      <td>User Maintenance</td>\n",
              "      <td>[badge, dear, please, help, assign, badge, sta...</td>\n",
              "      <td>[(badge, NN), (dear, NN), (please, NN), (help,...</td>\n",
              "      <td>[badge, dear, please, badge, today]</td>\n",
              "      <td>badge badge</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>12.125000</td>\n",
              "      <td>2</td>\n",
              "      <td>9.373264</td>\n",
              "      <td>0</td>\n",
              "      <td>0.202357</td>\n",
              "      <td>0</td>\n",
              "      <td>0.267989</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows Ã— 15 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-889bae7a-630e-4089-91d4-ccb3133b7f5e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-889bae7a-630e-4089-91d4-ccb3133b7f5e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-889bae7a-630e-4089-91d4-ccb3133b7f5e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5b574409-0f56-4029-9625-27e115ae2f2d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b574409-0f56-4029-9625-27e115ae2f2d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5b574409-0f56-4029-9625-27e115ae2f2d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"sent friday models hello revealed some models have serious vulnerability please open ticket for teams report what types used each solution one thus these devices should be used exceptionally thanks consultant\",\n          \"rd hello colleague joining rd please find attached regards officer\",\n          \"friday lost badge found hello written about lost badge which found morning possible activate back return newly given badge thank best regards software developer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Database\",\n          \"User Maintenance\",\n          \"Network\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tokenized\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos_tagged\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NN_tagged\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NN_Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 484,\n        \"samples\": [\n          \"floor part internship program officer\",\n          \"si va si si maine care si card va\",\n          \"monitor adapter adapter monitor somebody version release\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NN_WSP_Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NN_WSP_Value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5695481342384405,\n        \"min\": 0.0,\n        \"max\": 13.778645833333334,\n        \"num_unique_values\": 426,\n        \"samples\": [\n          11.177083333333334,\n          10.347222222222223\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WSP_Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WSP_Value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6059323914933501,\n        \"min\": 5.770833333333333,\n        \"max\": 10.900362318840573,\n        \"num_unique_values\": 490,\n        \"samples\": [\n          9.833333333333341,\n          9.59586247086247\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NN_WUP_Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NN_WUP_Value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05324061931925748,\n        \"min\": 0.0,\n        \"max\": 0.528422619047619,\n        \"num_unique_values\": 458,\n        \"samples\": [\n          0.28107031437272334,\n          0.25276217400650414\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WUP_Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WUP_Value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03296868100269994,\n        \"min\": 0.20558834932774236,\n        \"max\": 0.4840908272047011,\n        \"num_unique_values\": 498,\n        \"samples\": [\n          0.2506437826730263,\n          0.2124772271052603\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}